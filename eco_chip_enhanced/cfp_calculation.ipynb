{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and clean the base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = pd.read_excel('../dataset/DataSetWithRelaventNodesArea.xlsx')\n",
    "processors = processors.dropna(subset=['DieSizeValue', 'Die Size (mm^2)'], how='all')\n",
    "processors = processors[(processors['DieSizeValue'] != 0) | (processors['Die Size (mm^2)'] != 0)]\n",
    "processors = processors[processors['DieSizeValue'] != 'unknown']\n",
    "processors = processors[processors['Die Size (mm^2)'] != 'unknown']\n",
    "# Chiplet processors have different notations in die size value and die size\n",
    "chiplet = processors[processors['DieSizeValue'] != processors['Die Size (mm^2)']]\n",
    "\n",
    "\n",
    "processors = processors.drop(processors[processors['DieSizeValue'] != processors['Die Size (mm^2)']].index)\n",
    "processors = processors[processors['TDP (W)'].notna()]\n",
    "processors = processors[processors['TDP (W)'] != 'unknown']\n",
    "processors = processors[processors['TDP (W)'] != '0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic sequence generation\n",
    "# All probability distribution is based on referenced tech reports\n",
    "# sample_size is tunable, the resultant CFP values will not be significantly changed.\n",
    "## Reminder: We recommend use larger smaple size generating the parameter sequenceis for your CFP calculation. \n",
    "## However, for later probabilistic parameter sweep, we will sweep the parameter of Defective Density, GAP, EPA and Carbon Intensity each with sample_size.\n",
    "## To model N processors, we will have problem size of N x sample_size ^ 4 in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "ci_model_mean = 522.936\n",
    "ci_model_std = 19.826\n",
    "Idle_time = np.linspace(0.1, 1, 10)\n",
    "Life_time = np.linspace(0.5, 5, 10)\n",
    "ci_model = np.random.choice(np.arange(480.8486,546.7014,2.057901), size=sample_size, replace=True, p = [0.03125,0.03125,0.03125,0.03125,0.01041667,0.01041667,0.01041667,0.01041663,0.01041667,\n",
    "                                                                                                  0.01041667,0.01041667,0.01041667,0.01041667,0.01041667,0.01041667,\n",
    "                                                                                                  0.01041667,0.04166667,0.04166667,0.04166667,0.04166667,\n",
    "                                                                                                  0.02083333,0.02083333,0.02083333,0.02083333,0.0625,0.0625,\n",
    "                                                                                                  0.0625,0.0625,0.0625,0.0625,0.0625,0.0625])\n",
    "gpa_mean=150\n",
    "gpa_std=30\n",
    "\n",
    "gpa_model = np.random.normal(gpa_mean, gpa_std, sample_size)\n",
    "gpa_model = np.clip(gpa_model,50,300)\n",
    "\n",
    "\n",
    "Idle_time_mean = Idle_time.mean()\n",
    "Life_time_mean = Life_time.mean()\n",
    "\n",
    "defective_density_bench =  {\"7\": 0.2, \"10\": 0.11, \"14\":0.09, \"22\": 0.08, \"28\":0.07, \"65\":0.05}\n",
    "epa_bench =  {\"7\": 2.15, \"10\": 1.475, \"14\":1.2, \"22\": 1.2, \"28\":0.9}\n",
    "\n",
    "epa_distribution = [0.092478422,0.09864365,\n",
    "                    0.101726264,0.103575832,0.101726264,0.097410604,\n",
    "                    0.091245376,0.08323058,0.073982737,0.061652281,\n",
    "                    0.048088779,0.033908755,0.012330456,]\n",
    "\n",
    "defective_distribution=[0.1125,0.1125,0.1125,0.1125,0.1125,0.05,0.05,0.05,0.05,0.05,\n",
    "    0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,\n",
    "    0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,0.0125,]\n",
    "\n",
    "def distribution_modeling(bench, p, stride = 25, d1 = None, d2 = None):\n",
    "    d1 = 0.11 - 0.095\n",
    "    d2 = 0.42 - 0.11\n",
    "    defect_distribution = dict()\n",
    "    for node in bench:\n",
    "        defect_bench = defective_density_bench[node]\n",
    "        start = defect_bench - d1\n",
    "        end = defect_bench + d2\n",
    "        step = (end - start) / stride\n",
    "        defect_distribution[node] = np.random.choice(np.arange(start, end, step), size=sample_size, replace=True, p=p)\n",
    "\n",
    "    return defect_distribution\n",
    "\n",
    "def highest_probability(result):\n",
    "    unique_values, counts = np.unique(result, return_counts=True)\n",
    "    probabilities = counts / len(result)  # Convert frequency models to probabilities\n",
    "    # Find the maximum probability and its corresponding value\n",
    "    max_prob_index = np.argmax(probabilities)\n",
    "    max_prob_value = unique_values[max_prob_index]\n",
    "    max_prob = probabilities[max_prob_index]\n",
    "\n",
    "    return max_prob_value, max_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_model = distribution_modeling(defective_density_bench, defective_distribution)\n",
    "epa_model = distribution_modeling(epa_bench, epa_distribution, stride=13, d1 = 0.575, d2 = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in [7, 10, 14, 22, 28]:\n",
    "    print(f\"Node {node}:defect max {defect_model[str(node)].max():.3f}.,\" \n",
    "          f\"defect min {defect_model[str(node)].min():.3f}\",\n",
    "          f\"defct prob {highest_probability(defect_model[str(node)])[0]:.3f}\",\n",
    "          f\"epa max {epa_model[str(node)].max():.3f}\",\n",
    "          f\"epa min {epa_model[str(node)].min():.3f}\",\n",
    "          f\"epa prob {highest_probability(epa_model[str(node)])[0]:.3f}\")\n",
    "print(f\"ci_min {ci_model.min():.3f}, ci_max {ci_model.max():.3f} gpa_min {gpa_model.min():.3f}, gpa_max {gpa_model.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the generated probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = '10'\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.hist(defect_model[str(node)], bins=20, alpha=0.7, color='b')\n",
    "plt.xlabel('Defect Density')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Defect Density')\n",
    "\n",
    "# Plot histogram for gpa_model\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.hist(gpa_model, bins=20, alpha=0.7, color='r')\n",
    "plt.xlabel('GPA Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of GPA Values')\n",
    "\n",
    "# Plot histogram for ci_model\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.hist(ci_model, bins=20, alpha=0.7, color='g')\n",
    "plt.xlabel('Carbon Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Carbon Intensity')\n",
    "\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.hist(epa_model[node], bins=20, alpha=0.7, color='g')\n",
    "plt.xlabel('EPA')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of EPA')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFP calculation and export CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), \"eco_chip_enhanced/\"))\n",
    "\n",
    "from eco_chip_func import eco_chip\n",
    "\n",
    "for idx, proc in processors.iterrows():\n",
    "\n",
    "    # node = int(proc['Process Size (nm)'])\n",
    "    node = int(proc['Process Size (nm)'])\n",
    "    power = int(proc['TDP (W)'])\n",
    "    area = int(proc['DieSizeValue'])\n",
    "\n",
    "    # print(node, power, area)\n",
    "\n",
    "    defect_density = defect_model[str(node)].min()\n",
    "    epa_val = epa_model[str(node)].min()\n",
    "    gpa_val = gpa_model.min()\n",
    "    ci_val = ci_model.min()\n",
    "\n",
    "    args = argparse.Namespace(design_dir='testcases/CFP_survey/', \n",
    "                                chip_area=area, \n",
    "                                node=node, \n",
    "                                chip_power=power, \n",
    "                                defect_density=defect_density,\n",
    "                                num_lifetime=None, \n",
    "                                gpa = gpa_val, \n",
    "                                epa = epa_val,\n",
    "                                tech_scaling_path = None,\n",
    "                                carbon_intensity=ci_val)    \n",
    "    c_des, c_mfg, c_ope, c_tot = eco_chip(args)\n",
    "    min_emb = float(c_des) + float(c_mfg)\n",
    "    min_ope = c_ope\n",
    "    min_tot = min_emb + float(c_ope)\n",
    "    processors.at[idx, 'Emb Crabon Min'] = min_emb\n",
    "    processors.at[idx, 'Ope Carbon Min'] = min_ope\n",
    "    processors.at[idx, 'Tot Carbon Min'] = min_tot\n",
    "    processors.at[idx, 'ECFPA Min'] = min_emb / area\n",
    "    \n",
    "    defect_density = defect_model[str(node)].max()\n",
    "    epa_val = epa_model[str(node)].max()\n",
    "    gpa_val = gpa_model.max()\n",
    "    ci_val = ci_model.max()\n",
    "\n",
    "    args = argparse.Namespace(design_dir='testcases/CFP_survey/', \n",
    "                                chip_area=area, \n",
    "                                node=node, \n",
    "                                chip_power=power, \n",
    "                                defect_density=defect_density,\n",
    "                                num_lifetime=None, \n",
    "                                gpa = gpa_val, \n",
    "                                epa = epa_val,\n",
    "                                tech_scaling_path = None,\n",
    "                                carbon_intensity=ci_val)    \n",
    "\n",
    "    c_des, c_mfg, c_ope, c_tot = eco_chip(args)\n",
    "    max_emb = float(c_des) + float(c_mfg)\n",
    "    max_ope = c_ope\n",
    "    max_tot = max_emb + float(c_ope)\n",
    "\n",
    "    processors.at[idx, 'Emb Crabon Max'] = max_emb\n",
    "    processors.at[idx, 'Ope Carbon Max'] = max_ope\n",
    "    processors.at[idx, 'Tot Carbon Max'] = max_tot\n",
    "    processors.at[idx, 'ECFPA Max'] = max_emb / area\n",
    "\n",
    "    defect,_ =  highest_probability(defect_model[str(node)])\n",
    "    epa_val,_ = highest_probability(epa_model[str(node)])\n",
    "    gpa_val,_ = highest_probability(gpa_model)\n",
    "    ci_val, _=  highest_probability(ci_model)\n",
    "\n",
    "    args = argparse.Namespace(design_dir='testcases/CFP_survey/', \n",
    "                                chip_area=area, \n",
    "                                node=node, \n",
    "                                chip_power=power, \n",
    "                                defect_density=defect,\n",
    "                                num_lifetime=None, \n",
    "                                gpa = gpa_val, \n",
    "                                epa = epa_val,\n",
    "                                tech_scaling_path = None,\n",
    "                                carbon_intensity=ci_val)    \n",
    "    c_des, c_mfg, c_ope, c_tot = eco_chip(args)\n",
    "    emb = float(c_des) + float(c_mfg)\n",
    "    ope = c_ope\n",
    "    tot = emb + float(c_ope)\n",
    "\n",
    "\n",
    "    processors.at[idx, 'Emb Crabon Most Probable'] = emb\n",
    "    processors.at[idx, 'Ope Carbon Most Probable'] = ope\n",
    "    processors.at[idx, 'Tot Carbon Most Probable'] = tot\n",
    "    processors.at[idx, 'ECFPA Most Probable'] = emb / area\n",
    "\n",
    "\n",
    "print(\"CFP Process Finished\")\n",
    "# processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Chiplet and processed processors to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiplet['Emb Crabon Min'] = 'Insuficient Data'\n",
    "chiplet['Ope Carbon Min'] = 'Insuficient Data'\n",
    "chiplet['Tot Carbon Min'] = 'Insuficient Data'\n",
    "chiplet['ECFPA Min'] = 'Insuficient Data'\n",
    "\n",
    "chiplet['Emb Crabon Max'] = 'Insuficient Data'\n",
    "chiplet['Ope Carbon Max'] = 'Insuficient Data'  \n",
    "chiplet['Tot Carbon Max'] = 'Insuficient Data'\n",
    "chiplet['ECFPA Max'] = 'Insuficient Data'\n",
    "\n",
    "chiplet['Emb Crabon Most Probable'] = 'Insuficient Data'\n",
    "chiplet['Ope Carbon Most Probable'] = 'Insuficient Data'\n",
    "chiplet['Tot Carbon Most Probable'] = 'Insuficient Data'\n",
    "chiplet['ECFPA Most Probable'] = 'Insuficient Data'\n",
    "\n",
    "combined_df = pd.concat([chiplet, processors], ignore_index=True)\n",
    "combined_df.to_csv('../dataset/CarbonSet.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following code sneppts generate the probability CFP models for selected flagship processors. \n",
    "# 1 Latest model for both Desktop and Datacenter series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "# Add the src directory to sys.path\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "from eco_chip_func import eco_chip\n",
    "from CO2_func import *\n",
    "import argparse\n",
    "# sample_size = 3\n",
    "processor = {\"RTX 3090Ti\": [10, 450, 628], \"Intel Core i9-14900KF\": [10, 125, 257]\n",
    "        ,\"A100-SXM\": [7, 400, 826], \"Intel Xeon Platinum 8380\": [10, 270, 628]}\n",
    "\n",
    "def process_chip(i, j, k, m):\n",
    "    mfg_carbon = []\n",
    "    ope_carbon = []\n",
    "    tot_carbon = []\n",
    "    des_carbon = []\n",
    "    emb_carbon = []\n",
    "    name = []\n",
    "    for proc in processor:\n",
    "        node = processor[proc][0]\n",
    "        power = processor[proc][1]\n",
    "        area = processor[proc][2]\n",
    "        defect_density = defect_model[str(node)][i]\n",
    "        epa_val = epa_model[str(node)][j]\n",
    "        gpa_val = gpa_model[k]\n",
    "        ci_val = ci_model[m]\n",
    "\n",
    "        args = argparse.Namespace(design_dir='testcases/CFP_survey/', \n",
    "                                chip_area=area, \n",
    "                                node=node, \n",
    "                                chip_power=power, \n",
    "                                defect_density=defect_density,\n",
    "                                num_lifetime=None, \n",
    "                                gpa = gpa_val, \n",
    "                                epa = epa_val,\n",
    "                                tech_scaling_path = None,\n",
    "                                carbon_intensity=ci_val)    \n",
    "\n",
    "        c_des, c_mfg, c_ope, c_tot = eco_chip(args)\n",
    "        mfg_carbon.append(c_mfg)\n",
    "        ope_carbon.append(c_ope)\n",
    "        tot_carbon.append(c_tot)\n",
    "        des_carbon.append(c_des)\n",
    "        emb_carbon.append(float(c_des) + float(c_mfg))\n",
    "\n",
    "        name.append(proc)\n",
    "\n",
    "        local_df = pd.DataFrame({'Processor': name, \n",
    "                                 'Mfg_Carbon': mfg_carbon,\n",
    "                                 'Des_Carbon': des_carbon,\n",
    "                                 'Emb_Carbon': emb_carbon,\n",
    "                                 'Ope_Carbon': ope_carbon, \n",
    "                                 'Tot_Carbon': tot_carbon,\n",
    "                                 'Iteration': f\"{i} * {j} * {k} * {m}\"})\n",
    "        # print(f\"Finished iteration {i} {j} {k} {m}\")\n",
    "    return local_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caution\n",
    "\n",
    "The following cell initiates the probabilistic simulation of the selected flagship processors. The total problem size is calculated as ${sample\\ size}^4 \\times 4$. It is strongly recommended to reduce the `sample_size` parameter for a faster simulation process.\n",
    "\n",
    "Using a larger `sample_size` in prior steps ensures more stable CFP ranges, while a smaller `sample_size` during simulation maintains a reasonable probabilistic distribution of the CFP range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the parallel processing\n",
    "start = time.time()\n",
    "results = joblib.Parallel(n_jobs=-1)(joblib.delayed(process_chip)(i, j, k, m) for i in range(sample_size) \n",
    "                                     for j in range(sample_size) \n",
    "                                     for k in range(sample_size) \n",
    "                                     for m in range(sample_size))\n",
    "\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "end_time = time.time()  # End time for performance measurement\n",
    "elapsed_time = end_time - start\n",
    "\n",
    "print(f\"Elapsed time for processing: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the modeled results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert columns to numeric\n",
    "def convert_and_plot(df, model):\n",
    "    df['Emb_Carbon'] = pd.to_numeric(df['Emb_Carbon'])\n",
    "    df['Ope_Carbon'] = pd.to_numeric(df['Ope_Carbon'])\n",
    "    df['Tot_Carbon'] = pd.to_numeric(df['Tot_Carbon'])\n",
    "\n",
    "    # Plot histogram for Mfg_Carbon\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    df['Emb_Carbon'].plot(kind='hist', bins=50, density=True, alpha=0.6, color='b')\n",
    "    plt.xlabel('Emb_Carbon kgCO2e')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(f'Emb_Carbon Histogram of {model}')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    df['Ope_Carbon'].plot(kind='hist', bins=50, density=True, alpha=0.6, color='b')\n",
    "    plt.xlabel('Ope_carbon kgCO2e')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(f'OpeCarbon Histogram of {model}')\n",
    "\n",
    "    # Plot histogram for Tot_Carbon\n",
    "    plt.subplot(1, 3, 3)\n",
    "    df['Tot_Carbon'].plot(kind='hist', bins=50, density=True, alpha=0.6, color='g')\n",
    "    plt.xlabel('Tot_Carbon kgCO2e')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(f'Tot_Carbon Histogram of {model}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../plots/{model}-CFP-histogram.pdf\")\n",
    "    df.to_csv(f\"../dataset/{model}-CFP-histogram.csv\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def merged_plot(final_df, processor):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    # Plot histogram for Mfg_Carbon\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for model in processor:\n",
    "        df = final_df[final_df['Processor'] == model].copy()\n",
    "        df['Emb_Carbon'] = pd.to_numeric(df['Emb_Carbon'])\n",
    "        df['Emb_Carbon'].plot(kind='hist', bins=50, density=True, alpha=0.6, label=model)\n",
    "    plt.xlabel('Emb_Carbon kgCO2e')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Emb_Carbon Histogram')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for model in processor:\n",
    "        df = final_df[final_df['Processor'] == model].copy()\n",
    "        df['Ope_Carbon'] = pd.to_numeric(df['Ope_Carbon'])\n",
    "        df['Ope_Carbon'].plot(kind='hist', bins=50, density=True, alpha=0.6, label=model)\n",
    "    plt.xlabel('Ope_Carbon kgCO2e')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Ope_Carbon Histogram')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot histogram for Tot_Carbon\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for model in processor:\n",
    "        df = final_df[final_df['Processor'] == model].copy()\n",
    "        df['Tot_Carbon'] = pd.to_numeric(df['Tot_Carbon'])\n",
    "        df['Tot_Carbon'].plot(kind='hist', bins=50, density=True, alpha=0.6, label=model)\n",
    "    plt.xlabel('Tot_Carbon kgCO2e')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Tot_Carbon Histogram')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../plots/merged-probabilistic-histogram.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to PDF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in processor:\n",
    "    df = final_df[final_df['Processor'] == model].copy()\n",
    "    convert_and_plot(df, model)\n",
    "    \n",
    "merged_plot(final_df, processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the lifetime scaled overall CFP for selected flagship processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ['A100-SXM', 'Intel Core i9-14900KF', 'RTX 3090Ti', 'Intel Xeon Platinum 8380']\n",
    "scaling_factors = [0.8, 1, 1.2, 1.5, 1.8, 2, 2.4]\n",
    "\n",
    "for proc in processor:\n",
    "    file_path = f'dataset/{proc}-CFP-histogram.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "    # data = data.drop(columns=['Iteration', 'Yield', 'EPA', 'GPA', 'Defect', 'CI', 'CPA'])\n",
    "    ope_cfp = data['Ope_Carbon'].values.reshape(-1, 1) * scaling_factors\n",
    "    tot_cfp = data['Tot_Carbon'].values.reshape(-1 ,1) + ope_cfp\n",
    "    \n",
    "    ope_cfp = pd.DataFrame(ope_cfp,columns=[f'scaled_{factor}' for factor in scaling_factors])\n",
    "    tot_cfp = pd.DataFrame(tot_cfp, columns=[f'scaled_{factor}' for factor in scaling_factors])\n",
    "    \n",
    "    tot_cfp_combined = tot_cfp.values.flatten()\n",
    "    ope_cfp_combined = ope_cfp.values.flatten()\n",
    "\n",
    "    tot_cfp_combined = pd.DataFrame(tot_cfp_combined, columns=['Tot_Carbon'])\n",
    "    ope_cfp_combined = pd.DataFrame(ope_cfp_combined, columns=['Ope_Carbon'])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(tot_cfp_combined['Tot_Carbon'], bins=50, alpha=0.7)\n",
    "    plt.title('Total Carbon Footprint')\n",
    "    plt.xlabel('Carbon Footprint')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(ope_cfp_combined['Ope_Carbon'], bins=50, alpha=0.7)\n",
    "    plt.title('Operational Carbon Footprint')\n",
    "    plt.xlabel('Carbon Footprint')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.savefig(f\"plots/{proc}-scaled-CFP.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
